{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EELHfIrUmYfA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tO2dC7qgx4D6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "# Step 1: Data Preparation\n",
        "def unzip_files():\n",
        "    for zip_file in ['male1.zip', 'female.zip']:\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall()\n",
        "\n",
        "def augment_image(image):\n",
        "    # Flip horizontally\n",
        "    flipped = cv2.flip(image, 1)\n",
        "    # Rotate 90 degrees\n",
        "    rotated = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "    # Random brightness and contrast\n",
        "    alpha = 0.8 + random.uniform(0, 0.4)  # Contrast control (0.8-1.2)\n",
        "    beta = random.randint(-20, 20)  # Brightness control\n",
        "    adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "    return [image, flipped, rotated, adjusted]\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))  # Resize for VGG19\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Histogram equalization\n",
        "    gray = cv2.equalizeHist(gray)\n",
        "    # Contrast normalization\n",
        "    gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    # Convert back to color for VGG19\n",
        "    image = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
        "    image = preprocess_input(image)  # For VGG19\n",
        "    return image, gray\n",
        "\n",
        "def load_data():\n",
        "    images, grays, labels = [], [], []\n",
        "    # Count original images in each folder\n",
        "    male_count = len([f for f in os.listdir('male1') if f.endswith(('.jpg', '.png'))])\n",
        "    female_count = len([f for f in os.listdir('female') if f.endswith(('.jpg', '.png'))])\n",
        "    max_samples = min(male_count, female_count) * 4  # Max samples after augmentation (4 per image)\n",
        "\n",
        "    for folder, label in [('male1', 0), ('female', 1)]:\n",
        "        sample_count = 0\n",
        "        for filename in os.listdir(folder):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                if sample_count >= max_samples // 4:  # Limit to max original images\n",
        "                    break\n",
        "                img_path = os.path.join(folder, filename)\n",
        "                image, gray = preprocess_image(img_path)\n",
        "                # Augment images\n",
        "                augmented_images = augment_image(image)\n",
        "                augmented_grays = augment_image(gray)\n",
        "                images.extend(augmented_images)\n",
        "                grays.extend(augmented_grays)\n",
        "                labels.extend([label] * len(augmented_images))\n",
        "                sample_count += 1\n",
        "    return np.array(images), np.array(grays), np.array(labels)\n",
        "\n",
        "# Step 2: Feature Engineering\n",
        "def extract_hog_features(gray_images):\n",
        "    hog_features = []\n",
        "    for gray in gray_images:\n",
        "        features, hog_image = hog(gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
        "        hog_features.append(features)\n",
        "    return np.array(hog_features), hog_image\n",
        "\n",
        "def extract_lbp_features(gray_images):\n",
        "    lbp_features = []\n",
        "    lbp_image = None\n",
        "    for i, gray in enumerate(gray_images):\n",
        "        lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
        "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)\n",
        "        lbp_features.append(hist)\n",
        "        if i == 0:  # Save the first LBP for visualization\n",
        "            lbp_image = lbp\n",
        "    return np.array(lbp_features), lbp_image\n",
        "\n",
        "def extract_glcm_features(gray_images):\n",
        "    glcm_features = []\n",
        "    glcm_sample = None\n",
        "    for i, gray in enumerate(gray_images):\n",
        "        glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
        "        dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
        "        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
        "        glcm_features.append([contrast, dissimilarity, homogeneity])\n",
        "        if i == 0:  # Save the first GLCM features for visualization\n",
        "            glcm_sample = [contrast, dissimilarity, homogeneity]\n",
        "    return np.array(glcm_features), glcm_sample\n",
        "\n",
        "def visualize_features(hog_image, lbp_image, glcm_sample):\n",
        "    # Visualize HOG\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.imshow(hog_image, cmap='gray')\n",
        "    plt.title('HOG Visualization')\n",
        "    plt.axis('off')\n",
        "    plt.savefig('hog_visualization.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Visualize LBP\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.imshow(lbp_image, cmap='gray')\n",
        "    plt.title('LBP Visualization')\n",
        "    plt.axis('off')\n",
        "    plt.savefig('lbp_visualization.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Visualize GLCM features as a bar chart\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    glcm_labels = ['Contrast', 'Dissimilarity', 'Homogeneity']\n",
        "    plt.bar(glcm_labels, glcm_sample, color='skyblue')\n",
        "    plt.title('GLCM Features Visualization')\n",
        "    plt.ylabel('Value')\n",
        "    plt.savefig('glcm_visualization.png')\n",
        "    plt.close()\n",
        "\n",
        "def extract_vgg19_features(images):\n",
        "    # Load VGG19 with fully connected layers (include_top=True)\n",
        "    model = VGG19(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
        "    # Create models for fc2 and predictions layers\n",
        "    fc2_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('fc2').output)\n",
        "    pred_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('predictions').output)\n",
        "    # Extract features\n",
        "    fc2_features = fc2_model.predict(images, batch_size=32)\n",
        "    pred_features = pred_model.predict(images, batch_size=32)\n",
        "    # Concatenate features\n",
        "    vgg_features = np.concatenate((fc2_features, pred_features), axis=1)\n",
        "    return vgg_features\n",
        "\n",
        "# Step 3: Feature Fusion and Dimensionality Reduction\n",
        "def feature_fusion(hog, lbp, glcm, vgg19):\n",
        "    # Serial-based fusion\n",
        "    low_level = np.hstack((hog, lbp, glcm))\n",
        "    fused = np.hstack((low_level, vgg19))\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    fused = scaler.fit_transform(fused)\n",
        "    # PCA\n",
        "    pca = PCA(n_components=0.95)  # Retain 95% variance\n",
        "    fused_reduced = pca.fit_transform(fused)\n",
        "    # Visualize PCA explained variance\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(range(len(pca.explained_variance_ratio_)), pca.explained_variance_ratio_, color='skyblue')\n",
        "    plt.title('PCA Explained Variance Ratio')\n",
        "    plt.xlabel('Principal Component')\n",
        "    plt.ylabel('Explained Variance Ratio')\n",
        "    plt.savefig('pca_variance.png')\n",
        "    plt.close()\n",
        "    return fused_reduced\n",
        "\n",
        "# Step 4 & 5: Classification and Evaluation\n",
        "def classify_and_evaluate(features, labels):\n",
        "    # Use class_weight='balanced' to handle class imbalance\n",
        "    svm = LinearSVC(max_iter=10000, class_weight='balanced')\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    accuracies, precisions, recalls, f1s = [], [], [], []\n",
        "    all_y_true, all_y_pred = [], []\n",
        "\n",
        "    for train_idx, test_idx in kf.split(features):\n",
        "        X_train, X_test = features[train_idx], features[test_idx]\n",
        "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "        svm.fit(X_train, y_train)\n",
        "        y_pred = svm.predict(X_test)\n",
        "\n",
        "        accuracies.append(accuracy_score(y_test, y_pred))\n",
        "        precisions.append(precision_score(y_test, y_pred, average='binary'))\n",
        "        recalls.append(recall_score(y_test, y_pred, average='binary'))\n",
        "        f1s.append(f1_score(y_test, y_pred, average='binary'))\n",
        "\n",
        "        all_y_true.extend(y_test)\n",
        "        all_y_pred.extend(y_pred)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
        "    print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n",
        "    print(f\"Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n",
        "    print(f\"F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_y_true, all_y_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Male', 'Female'], yticklabels=['Male', 'Female'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig('confusion_matrix.png')\n",
        "    plt.close()\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Unzip files\n",
        "    unzip_files()\n",
        "\n",
        "    # Load and preprocess data\n",
        "    images, grays, labels = load_data()\n",
        "\n",
        "    # Extract features and get visualizations for the first image\n",
        "    hog_features, hog_image = extract_hog_features(grays)\n",
        "    lbp_features, lbp_image = extract_lbp_features(grays)\n",
        "    glcm_features, glcm_sample = extract_glcm_features(grays)\n",
        "    vgg19_features = extract_vgg19_features(images)\n",
        "\n",
        "    # Visualize HOG, LBP, and GLCM for the first image\n",
        "    visualize_features(hog_image, lbp_image, glcm_sample)\n",
        "\n",
        "    # Feature fusion and dimensionality reduction\n",
        "    fused_features = feature_fusion(hog_features, lbp_features, glcm_features, vgg19_features)\n",
        "\n",
        "    # Classify and evaluate\n",
        "    classify_and_evaluate(fused_features, labels)"
      ],
      "metadata": {
        "id": "1p7A1Bp08YQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a08cba-f90d-4a39-a6ec-e26b007e3064"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 192ms/step\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 197ms/step\n",
            "Accuracy: 0.8311 ± 0.0265\n",
            "Precision: 0.8257 ± 0.0512\n",
            "Recall: 0.8344 ± 0.0331\n",
            "F1-Score: 0.8295 ± 0.0378\n"
          ]
        }
      ]
    }
  ]
}